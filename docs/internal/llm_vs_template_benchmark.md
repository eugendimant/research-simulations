# LLM vs Template Engine: Side-by-Side Benchmark

**Generated**: 2026-02-08 19:20 UTC
**Version**: 1.4.10

## Overview

This document compares open-ended survey responses generated by **three LLM providers**
and the **built-in template engine** (225+ domains, 40 question types) across 6 different
question types extracted from real Qualtrics QSF files used in behavioral science courses.

### Providers Tested

| Provider | Model | Free Tier |
|----------|-------|-----------|
| **Groq** (built-in) | `llama-3.3-70b-versatile` | 14,400 requests/day |
| **Cerebras** (built-in) | `llama-3.3-70b` | 1M tokens/day |
| **OpenRouter** (built-in) | `meta-llama/llama-3.3-70b-instruct:free` | Free models |
| **Template Engine** (fallback) | N/A — rule-based | Unlimited, no API needed |

### Persona Profiles Used

| # | Persona | Verbosity | Formality | Engagement | Sentiment |
|---|---------|-----------|-----------|------------|-----------|
| 1 | Engaged (formal) | 0.75 | 0.80 | 0.90 | positive |
| 2 | Casual (brief) | 0.25 | 0.15 | 0.55 | neutral |
| 3 | Thoughtful (verbose) | 0.85 | 0.60 | 0.85 | negative |
| 4 | Satisficer (minimal) | 0.10 | 0.40 | 0.20 | neutral |
| 5 | Enthusiastic (casual) | 0.65 | 0.20 | 0.90 | very_positive |

---

## Q1: Description Question

**Source QSF**: `Coffee_Shop_Loyalty_Programs.qsf`  
**Study**: Coffee Shop Loyalty Programs  
**Condition**: Points-based loyalty program (200 points for reward)  
**Question**: *"In 1-2 sentences, please describe what you see in the loyalty program above:"*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> The framing helped me see it positively, as I see it. Looking at this from different perspectives helps clarify my view, I think. Frankly, that's my take on it.

**Persona 2** (Casual (brief), neutral):
> I didn't pay much attention to the wording, in my view.

**Persona 3** (Thoughtful (verbose), negative):
> Reflecting on this, i would say the framing highlighted the downsides. Furthermore, it just makes sense to me, to my mind. There's room for improvement, in my view.

**Persona 4** (Satisficer (minimal), neutral):
> Honestly, i focused on.

**Persona 5** (Enthusiastic (casual), very_positive):
> The really positive framing influenced my favorable view, I think.

*Stats: 0.003s, avg 94 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.1s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Q2: Evaluation Question

**Source QSF**: `0401_Backlash_aftermath_performance_pilot.qsf`  
**Study**: Gender Backlash in Salary Negotiation  
**Condition**: Female candidate / assertive negotiation style  
**Question**: *"What is your overall impression of the job candidate based on how they negotiated the offer?"*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> I've found that the offer seemed reasonable enough to accept. On top of that, it just makes sense to me, as I see it. What strikes me is that hopefully that makes sense.

**Persona 2** (Casual (brief), neutral):
> Generally speaking, didn't think too hard about it, I think.

**Persona 3** (Thoughtful (verbose), negative):
> Looking at this, i accepted even though it felt unfair. Frankly, i expected better.

**Persona 4** (Satisficer (minimal), neutral):
> My sense is that i wasn't sure.

**Persona 5** (Enthusiastic (casual), very_positive):
> I basically accepted because the offer was fair and respectful, I think.

*Stats: 0.006s, avg 83 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Q3: Explanation Question

**Source QSF**: `DG & PGG (Information Nudge).qsf`  
**Study**: Dictator Game with Information Nudge  
**Condition**: Social information nudge (told average donation is 40%)  
**Question**: *"Please explain your choice in a few sentences:"*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> My gut feeling is that regarding my choice, there were good reasons for this result. Genuinely, i think this reflects broader patterns in how people think. Realistically, i think that covers the main points.

**Persona 2** (Casual (brief), neutral):
> Speaking from experience, that regarding my choice, the causes aren't entirely clear.

**Persona 3** (Thoughtful (verbose), negative):
> Regarding my choice, i don't think effort mattered much, I think. From what I can tell, i've given this some thought and considered different angles. In truth, this could be handled differently.

**Persona 4** (Satisficer (minimal), neutral):
> To be fair, as I see it, regarding my choice.

**Persona 5** (Enthusiastic (casual), very_positive):
> In my view, considering my options, regarding my choice, the success was due to skill and effort.

*Stats: 0.002s, avg 126 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Q4: Opinion/Belief Question

**Source QSF**: `!!Human-AI_Interaction_Template.qsf`  
**Study**: Human-AI Interaction and Trust  
**Condition**: AI-generated advice condition  
**Question**: *"Reflecting on this, are there any specific concerns or hopes you have about AI in everyday decision-making? Please describe one below and share your reasons."*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> When making this decision, i responded to the way it was presented, in my view. Frankly, plus, I feel fairly strongly about this. My sense is that that covers the main points.

**Persona 2** (Casual (brief), neutral):
> From my perspective, regarding my decision, the framing seemed neutral to me, in my view.

**Persona 3** (Thoughtful (verbose), negative):
> After thinking about it, regarding my decision, the framing highlighted the downsides. In truth, there's room for improvement.

**Persona 4** (Satisficer (minimal), neutral):
> Regarding my decision, as I see it.

**Persona 5** (Enthusiastic (casual), very_positive):
> In my estimation, that regarding my decision, the positive framing influenced my favorable view. Plus, that's my perspective, from my perspective.

*Stats: 0.003s, avg 114 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Q5: Meta/Suspicion Question

**Source QSF**: `0401_Backlash_aftermath_performance_pilot.qsf`  
**Study**: Gender Backlash in Salary Negotiation  
**Condition**: Male candidate / collaborative negotiation style  
**Question**: *"What do you think this study was about?"*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> What strikes me is that learning is generally positive. My initial thought is that that covers the main points.

**Persona 2** (Casual (brief), neutral):
> My gut feeling is that i don't honestly think much about learning.

**Persona 3** (Thoughtful (verbose), negative):
> In truth, learning takes too much effort. nevertheless, i've given this some thought and considered different angles, as I see it. I suspect that i expected better.

**Persona 4** (Satisficer (minimal), neutral):
> My position is that i don't think.

**Persona 5** (Enthusiastic (casual), very_positive):
> I find learning deeply rewarding, from my perspective.

*Stats: 0.003s, avg 86 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Q6: Feedback Question

**Source QSF**: `DG & PGG (Information Nudge).qsf`  
**Study**: Dictator Game with Information Nudge  
**Condition**: Control (no nudge)  
**Question**: *"Feedback: Was there anything confusing about the experiment? Was anything unclear? If so, please let us know."*

### Template Engine

**Persona 1** (Engaged (formal), positive):
> Realistically, generally speaking, good value for the price. My position is that looking at this from different perspectives helps clarify my view. Genuinely, that's how I see it anyway.

**Persona 2** (Casual (brief), neutral):
> To be fair, as I sort of see it, neither impressed nor disappointed.

**Persona 3** (Thoughtful (verbose), negative):
> Speaking from experience, probably won't buy again. Realistically, moreover, I feel fairly strongly about this. This could be handled differently, to my mind.

**Persona 4** (Satisficer (minimal), neutral):
> I'd say standard quality.

**Persona 5** (Enthusiastic (casual), very_positive):
> This product exceeded all my expectations, to my mind.

*Stats: 0.005s, avg 98 chars, 100% unique*

### Groq (`llama-3.3-70b-versatile`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### Cerebras (`llama-3.3-70b`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

### OpenRouter (`meta-llama/llama-3.3-70b-instruct:free`)

*API call failed (0.0s) — provider may be rate-limited or unreachable from this environment.*

---

## Aggregate Statistics

| Provider | Avg Time/Question | Avg Response Length | Avg Uniqueness | Questions Answered |
|----------|-------------------|--------------------|----------------|-------------------|
| Groq | N/A | N/A | N/A | 0/6 |
| Cerebras | N/A | N/A | N/A | 0/6 |
| OpenRouter | N/A | N/A | N/A | 0/6 |
| Template | 0.00s | 100 chars | 100% | 6/6 |

## Architecture Comparison

| Dimension | LLM Providers | Template Engine |
|-----------|---------------|-----------------|
| **How it works** | Sends persona-parameterized prompts to Llama 3.3 70B | Selects from 225+ domain templates, applies 7-layer persona variation |
| **Response quality** | High — natural, context-aware, condition-specific | Good — domain-matched, persona-varied, grammatically correct |
| **Persona fidelity** | Excellent — LLM follows verbosity/formality/engagement | Good — template selection + post-processing transformations |
| **Condition reference** | Often references experimental condition explicitly | Uses condition for template category selection |
| **Speed** | 2-5s per batch of 20 | <0.001s per response |
| **Reliability** | 3-provider chain (Groq → Cerebras → OpenRouter) | 100% — no external dependencies |
| **Cost** | Free (built-in keys, ~14K+ requests/day combined) | Free |
